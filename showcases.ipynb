{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| entity | semantic |\n",
    "|-|-|\n",
    "| `data_` | dataframes containing both raw data and targets |\n",
    "| `i_` | indices in `data_` objects |\n",
    "| `y_` | targets |\n",
    "| `f_` | features |\n",
    "| `p_` | predictions of models (incl. cross-validated) |\n",
    "| `q_` | quality metrics (log loss) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pandas.read_csv('./input/train.csv')\n",
    "data_test = pandas.read_csv('./input/test.csv')\n",
    "data = pandas.concat([data_train, data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.author\n",
    "\n",
    "i_train = ~y.isnull()\n",
    "i_test = y.isnull()\n",
    "\n",
    "y_train = y[i_train]\n",
    "y_test = y[i_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_words(s):\n",
    "    return re.findall(r'\\w+', s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words(s):\n",
    "    return re.findall(r'\\w+', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_words = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len(lower_case_words(s)))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_unique_words = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len(set(lower_case_words(s))))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_chars = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len(s))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_stopwords = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len([\n",
    "        w\n",
    "        for w in lower_case_words(s)\n",
    "        if w in english_stopwords\n",
    "    ]))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of punctuation characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_punct = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len([\n",
    "        c\n",
    "        for c in s\n",
    "        if c in string.punctuation\n",
    "    ]))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of upper-case words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_upper_words = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len([\n",
    "        w\n",
    "        for w in all_words(s)\n",
    "        if w.isupper()\n",
    "    ]))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of title-case words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_n_title_words = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: len([\n",
    "        w\n",
    "        for w in all_words(s)\n",
    "        if w.istitle()\n",
    "    ]))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean length of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean_word_length = (\n",
    "    data[\"text\"]\n",
    "    .apply(lambda s: numpy.mean([\n",
    "        len(w)\n",
    "        for w in all_words(s)\n",
    "    ]))\n",
    "    .as_matrix()\n",
    "    [:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_features = (\n",
    "    f_n_words,\n",
    "    f_n_unique_words,\n",
    "    f_n_chars,\n",
    "    f_n_stopwords,\n",
    "    f_n_punct,\n",
    "    f_n_upper_words,\n",
    "    f_n_title_words,\n",
    "    f_mean_word_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_basic_features = numpy.hstack(basic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tfidf = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_tfidf = t_tfidf.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_svd = TruncatedSVD(n_components=n_comp, algorithm=\"arpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_svd = t_svd.fit_transform(f_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_count = CountVectorizer(stop_words=\"english\", ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_count = t_count.fit_transform(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(\n",
    "    model,\n",
    "    features,\n",
    "    evaluate=True,\n",
    "    predict=False,\n",
    "):\n",
    "    if any(map(\n",
    "        lambda z: type(z) is scipy.sparse.csr_matrix,\n",
    "        features,\n",
    "    )):\n",
    "        hstack = scipy.sparse.hstack\n",
    "    else:\n",
    "        hstack = numpy.hstack\n",
    "    \n",
    "    f_all = hstack(features)\n",
    "    f_train = f_all[numpy.nonzero(i_train)]\n",
    "    f_test = f_all[numpy.nonzero(i_test)]\n",
    "    \n",
    "    p_cv = cross_val_predict(model, f_train, y_train, cv=cv, method=\"predict_proba\")\n",
    "    q_cv = log_loss(y_train, p_cv)\n",
    "    \n",
    "    model.fit(f_train, y_train)\n",
    "    \n",
    "    p_train = model.predict_proba(f_train)\n",
    "    q_train = log_loss(y_train, p_train)\n",
    "    \n",
    "    if evaluate:\n",
    "        print(f\"train log loss = {q_train:.5f}\")\n",
    "        print(f\"   cv log loss = {q_cv:.5f}\")\n",
    "        print()\n",
    "    \n",
    "    if predict:\n",
    "        p_test = model.predict_proba(f_test)\n",
    "        p_full = numpy.concatenate((p_cv, p_test), axis=0)\n",
    "        return pandas.DataFrame(p_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lr_basic = apply_model(\n",
    "    LogisticRegression(max_iter=10),\n",
    "    basic_features,\n",
    "    predict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(\n",
    "    LogisticRegression(max_iter=10),\n",
    "    (f_tfidf, ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(\n",
    "    MultinomialNB(),\n",
    "    (f_tfidf, ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(\n",
    "    MultinomialNB(),\n",
    "    (f_count, ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in [1, 3, 10, 30, 100, 300]:\n",
    "    print(f'{x} estimators:')\n",
    "    apply_model(\n",
    "        XGBClassifier(n_estimators=x),\n",
    "        basic_features,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [1, 3, 10, 30, 100, 300]:\n",
    "    print(f'{x} estimators:')\n",
    "    apply_model(\n",
    "        XGBClassifier(n_estimators=x),\n",
    "        (f_svd, ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With LR predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(\n",
    "    XGBClassifier(n_estimators=10),\n",
    "    basic_features + (p_lr_base, ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
